{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3513,"status":"ok","timestamp":1743710651687,"user":{"displayName":"Mark Watson","userId":"11467267828871245451"},"user_tz":420},"id":"6-yX81d7x1Sv","outputId":"2e877210-cbb4-4a5e-855f-6a2b35548b74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import torch\n","import numpy as np\n","from google.colab import drive\n","import re\n","import torchvision\n","import pandas as pd\n","import cv2\n","from torch.utils.data import DataLoader, TensorDataset\n","import numpy as np\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from IPython.display import clear_output\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir('/content/drive/Shareddrives/Strawberries/Image experiment')\n","\n","embedding_size = 16"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozF1_DRcxcdj"},"outputs":[],"source":["# Function to convert a tensor to an image\n","def to_img(x):\n","    return np.moveaxis(x.numpy() * 255, 0, -1).astype(np.uint8)\n","\n","# Function to get the length-to-width ratio of the largest contour in an image\n","def getLWR(img):\n","    # Convert image to grayscale if it has more than one channel\n","    if img.shape[2] > 1:\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # Add a constant border to the image\n","    img = cv2.copyMakeBorder(img, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=0)\n","    # Apply binary thresholding\n","    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","    # Invert image if the background is white\n","    if img[0, 0] == 255:\n","        img = cv2.bitwise_not(img)\n","    # Find contours in the image\n","    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    # Get the largest contour by area\n","    contour = max(contours, key=cv2.contourArea)\n","    # Get dimensions of the minimum area rectangle enclosing the contour\n","    w, h = cv2.minAreaRect(contour)[1]\n","    # Return the length-to-width ratio\n","    return max(w, h) / min(w, h)\n","\n","def getShapeIndex(img):\n","      # Convert image to grayscale if it has more than one channel\n","    if img.shape[2] > 1:\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # Add a constant border to the image\n","    img = cv2.copyMakeBorder(img, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=0)\n","    # Apply binary thresholding\n","    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","    # Invert image if the background is white\n","    if img[0, 0] == 255:\n","        img = cv2.bitwise_not(img)\n","    # Find contours in the image\n","    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    # Get the largest contour by area\n","    contour = max(contours, key=cv2.contourArea)\n","    # Initialize variables to store the max width and corresponding height\n","    max_width = 0\n","    max_height = 0\n","    point1 = None\n","    point2 = None\n","    # Iterate through each pair of points in the contour\n","    for i in range(len(contour)):\n","        for j in range(i + 1, len(contour)):\n","            # Calculate the distance between the two points in both x and y directions\n","            dx = contour[j][0][0] - contour[i][0][0]\n","            dy = contour[j][0][1] - contour[i][0][1]\n","            # If the distance in the x direction (width) is the largest we've seen\n","            width = abs(dx)\n","            if width > max_width:\n","                max_width = width\n","                max_height = abs(dy)  # The corresponding height (vertical distance)\n","                point1 = contour[i][0]\n","                point2 = contour[j][0]\n","    return max_height / max_width\n","\n","def getMeanNonBlackColor(img):\n","  data = img.reshape(-1, img.shape[-1])\n","  data = data[np.array([np.all(i != [0,0,0]) for i in data])]\n","  return np.mean(data, axis = 0)\n","\n","def getRedness(img):\n","  # image should be rgb\n","  data = img.reshape(-1, img.shape[-1])\n","  data = data[np.array([np.all(i != [0,0,0]) for i in data])]\n","  # redness is distance from (160,20,20)\n","  distances = np.linalg.norm(data - [160,20,20], axis = 1)\n","  distances = 255 - np.mean(distances)\n","  return distances\n","\n","# Hyperparameters\n","image_size = (100, 100, 3)  # Dimensions of input images (height, width, channels)\n","\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","        self.fc1 = nn.Linear(np.prod(image_size), 400)  # Input layer to hidden layer\n","        self.fc21 = nn.Linear(400, embedding_size)  # Hidden layer to mean of latent space\n","        self.fc22 = nn.Linear(400, embedding_size)  # Hidden layer to log variance of latent space\n","        self.fc3 = nn.Linear(embedding_size, 400)  # Latent space to hidden layer\n","        self.fc4 = nn.Linear(400, np.prod(image_size))  # Hidden layer to output layer\n","\n","    # Encode function to obtain mean and log variance of the latent space\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1(x))\n","        return self.fc21(h1), self.fc22(h1)\n","\n","    # Reparametrization trick to sample from the latent space\n","    def reparametrize(self, mu, logvar):\n","        std = logvar.mul(0.5).exp_()  # Compute standard deviation\n","        # Generate random noise\n","        if torch.cuda.is_available():\n","            eps = torch.cuda.FloatTensor(std.size()).normal_()\n","        else:\n","            eps = torch.FloatTensor(std.size()).normal_()\n","        eps = Variable(eps)\n","        return eps.mul(std).add_(mu)  # Return the sampled latent vector\n","\n","    # Decode function to reconstruct the image from the latent vector\n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        return torch.sigmoid(self.fc4(h3))\n","\n","    # Forward pass through the VAE\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparametrize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","\n","def take_mean(df, accessions):\n","    df = pd.DataFrame(df)\n","    df['Accession'] = accessions\n","    df_grouped = df.groupby('Accession').mean()  # Automatically handles NaN with .mean()\n","    return df_grouped.reset_index(drop=True) # Reset index and drop the Accession column\n","\n","images = torch.load('fullImages.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GaKsZpDwxkqb"},"outputs":[],"source":["for random_seed in list(range(1,50)):\n","\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  model = VAE()\n","  model.to(device)\n","  model.load_state_dict(torch.load(str(random_seed) + \"_vae_\" + str(embedding_size) + \".pth\", map_location=torch.device('cpu')))\n","\n","  print(random_seed)\n","\n","  trainKey = np.genfromtxt(f\"{random_seed}_trainKey.csv\", delimiter=',', skip_header=0)\n","  testKey = np.genfromtxt(f\"{random_seed}_testKey.csv\", delimiter=',', skip_header=0)\n","  phenotypes = pd.read_csv(\"fullPhenotypes.csv\")\n","  rrBLUPpredictedTraits = pd.read_csv(str(random_seed) + '_rrBLUPpredictedTraits' + '.csv')\n","\n","  accessions = trainKey.copy()\n","  accessions[testKey >= 0] = testKey[testKey >= 0]\n","\n","  trainKey = take_mean(trainKey, accessions).to_numpy().flatten()\n","  testKey = take_mean(testKey, accessions).to_numpy().flatten()\n","  phenotypes = take_mean(phenotypes, accessions)\n","  rrBLUPpredictedTraits = take_mean(rrBLUPpredictedTraits, accessions)\n","\n","  trainKey = trainKey >= 0\n","  testKey = testKey >= 0\n","\n","  rrBLUPPredictedEmbeddings = torch.tensor(pd.read_csv(str(random_seed) + '_rrBLUPpredictedEmbeddings_' + str(embedding_size) + '.csv').to_numpy(), dtype = torch.float32)\n","  endToEndLWRs = []\n","  endToEndShapeIndices = []\n","  endToEndBs = []\n","  endToEndGs = []\n","  endToEndRs = []\n","  endToEndRednesses = []\n","  endToEndImages = []\n","  endToEndRandoms = []\n","\n","  for i in range(len(rrBLUPPredictedEmbeddings)):\n","    # print(str(i) + ' out of ' + str(len(rrBLUPPredictedEmbeddings)))\n","    rrBLUPPredictedEmbedding = rrBLUPPredictedEmbeddings[i,:]\n","    # predictedEmbedding = torch.tensor(np.random.normal(size=test_loader.dataset.tensors[1][i].shape).astype(np.float32))\n","    # predictedEmbedding = test_loader.dataset.tensors[1][i]\n","    endToEndImage = model.decode(rrBLUPPredictedEmbedding.to(device))\n","    endToEndImage = endToEndImage.view(1, -1)\n","    endToEndImage = to_img(endToEndImage.cpu().detach().view(image_size[::-1]))\n","    # plt.figure()\n","    # plt.imshow(cv2.cvtColor(endToEndImage,  cv2.COLOR_BGR2RGB))\n","    # plt.pause(0.0001)\n","    endToEndLWR = getLWR(endToEndImage)\n","    endToEndLWRs.append(endToEndLWR)\n","    endToEndShapeIndex = getShapeIndex(endToEndImage)\n","    endToEndShapeIndices.append(endToEndShapeIndex)\n","    endToEndB, endToEndG, endToEndR = getMeanNonBlackColor(cv2.cvtColor(endToEndImage,  cv2.COLOR_BGR2RGB))\n","    endToEndBs.append(endToEndB)\n","    endToEndGs.append(endToEndG)\n","    endToEndRs.append(endToEndR)\n","    endToEndRedness = getRedness(cv2.cvtColor(endToEndImage,  cv2.COLOR_BGR2RGB))\n","    endToEndRednesses.append(endToEndRedness)\n","    endToEndRandoms.append(np.random.normal(size=1)[0])\n","    endToEndImages.append(endToEndImage)\n","\n","  torch.save(endToEndImages, str(random_seed) + '_endToEndImages.pt')\n","\n","  endToEndLWRs = np.array(endToEndLWRs)\n","  endToEndShapeIndices = np.array(endToEndShapeIndices)\n","  endToEndBs = np.array(endToEndBs)\n","  endToEndGs = np.array(endToEndGs)\n","  endToEndRs = np.array(endToEndRs)\n","  endToEndRednesses = np.array(endToEndRednesses)\n","  endToEndRandoms = np.array(endToEndRandoms)\n","  endToEndPhenotypes = phenotypes * 0\n","  endToEndPhenotypes['LWR'] = endToEndLWRs\n","  endToEndPhenotypes['ShapeIndex'] = endToEndShapeIndices\n","  endToEndPhenotypes['B'] = endToEndBs\n","  endToEndPhenotypes['G'] = endToEndGs\n","  endToEndPhenotypes['R'] = endToEndRs\n","  endToEndPhenotypes['Redness'] = endToEndRednesses\n","  endToEndPhenotypes['Random'] = endToEndRandoms\n","\n","  for trait in phenotypes.columns.values:\n","    print(trait)\n","    traditionalTestAccuracy = np.corrcoef(rrBLUPpredictedTraits[trait].values[testKey], phenotypes[trait].values[testKey])[0,1] ** 2\n","    endToEndTestAccuracy = np.corrcoef(endToEndPhenotypes[trait].values[testKey], phenotypes[trait].values[testKey])[0,1] ** 2\n","    print(traditionalTestAccuracy)\n","    print(endToEndTestAccuracy)\n","    print(endToEndTestAccuracy / traditionalTestAccuracy)\n","\n","    df = pd.DataFrame(np.concatenate([endToEndPhenotypes[trait].values[testKey], rrBLUPpredictedTraits[trait].values[testKey]]), columns = ['predicted'])\n","    df['method'] = np.concatenate([np.repeat('end-to-end', len(endToEndPhenotypes[trait].values[testKey])), np.repeat('traditional', len(rrBLUPpredictedTraits[trait].values[testKey]))])\n","    df['known'] = np.concatenate([phenotypes[trait].values[testKey], phenotypes[trait].values[testKey]])\n","    fig = px.scatter(df, x = 'predicted', y = 'known', color = 'method', title = trait)\n","    fig.add_trace(go.Scatter(\n","        x=[np.min(phenotypes[trait].values[testKey]), np.max(phenotypes[trait].values[testKey])],\n","        y=[np.min(phenotypes[trait].values[testKey]), np.max(phenotypes[trait].values[testKey])],\n","        name = 'predicted = known',\n","    ))\n","    fig.show()\n","\n","    # save df as csv\n","    # df.to_csv(str(random_seed) + '_' + trait + '_correlations.csv', index = False)"]},{"cell_type":"code","source":["allFlattenedImages = np.array([to_img(i).flatten() for i in images])\n","\n","for random_seed in list(range(1,50)):\n","\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","  model = VAE()\n","  model.to(device)\n","  model.load_state_dict(torch.load(str(random_seed) + \"_vae_\" + str(embedding_size) + \".pth\", map_location=torch.device('cpu')))\n","\n","  embeddings = torch.load(str(random_seed) + \"_embeddings_\" + str(embedding_size) + \".pt\")\n","\n","  trainKey = np.genfromtxt(f\"{random_seed}_trainKey.csv\", delimiter=',', skip_header=0)\n","  testKey = np.genfromtxt(f\"{random_seed}_testKey.csv\", delimiter=',', skip_header=0)\n","  phenotypes = pd.read_csv(\"fullPhenotypes.csv\")\n","  rrBLUPpredictedTraits = pd.read_csv(str(random_seed) + '_rrBLUPpredictedTraits' + '.csv')\n","\n","  accessions = trainKey.copy()\n","  accessions[testKey >= 0] = testKey[testKey >= 0]\n","\n","  trainKey = take_mean(trainKey, accessions).to_numpy().flatten()\n","  testKey = take_mean(testKey, accessions).to_numpy().flatten()\n","\n","  trainKey = trainKey >= 0\n","  testKey = testKey >= 0\n","\n","  all_cors = []\n","  all_randomCors = []\n","  endToEndImages = np.array(torch.load(str(random_seed) + '_endToEndImages.pt', weights_only = False))\n","  improvements = []\n","  for i in np.where(testKey)[0]:\n","      theseImages = images[accessions == i]\n","      theseEmbeddings = embeddings[accessions == i]\n","      theseImages = [model.decode(i.to(device)).view(1,-1).cpu().detach().view(image_size[::-1]) for i in theseEmbeddings]\n","\n","      n_images = len(theseImages) + 1\n","      side_length = int(np.ceil(np.sqrt(n_images)))\n","      side_length = 6\n","      mosaic_size = side_length * 100\n","      mosaic = np.zeros((mosaic_size, mosaic_size, 3), dtype=np.uint8)\n","\n","      distances = []\n","      cors = []\n","      randomDistances = []\n","      randomCors = []\n","      for j in range(side_length ** 2):\n","\n","          thisEndToEndImage = endToEndImages[i]\n","          thisRandomImage = endToEndImages[np.random.randint(len(endToEndImages))]\n","          # thisRandomImage = to_img(images[np.random.randint(len(images))])\n","\n","          x = (j % side_length) * 100\n","          y = (j // side_length) * 100\n","\n","          if (j >= len(theseImages)) or (j >= (side_length ** 2) - 1):\n","            thisImage = thisEndToEndImage\n","          else:\n","            thisImage = to_img(theseImages[j])\n","            # get euclidean distance between theseImages[j] and thisEndToEndImage\n","            # distance = np.linalg.norm(thisImage.flatten() - thisEndToEndImage.flatten())\n","            distance = np.mean((thisImage.flatten() - thisEndToEndImage.flatten()) ** 2)\n","            distances.append(distance)\n","            cor = np.corrcoef(thisImage.flatten(), thisEndToEndImage.flatten())[0, 1] ** 2\n","            cors.append(cor)\n","            # randomDistance = np.linalg.norm(thisImage.flatten() - thisRandomImage.flatten())\n","            randomDistance = np.mean((thisImage.flatten() - thisRandomImage.flatten()) ** 2)\n","            # randomDistance = np.array(([np.mean((thisImage.flatten() - thisRandomImage) ** 2) for thisRandomImage in allFlattenedImages]))\n","            randomDistances.append(randomDistance)\n","            randomCor = np.corrcoef(thisImage.flatten(), thisRandomImage.flatten())[0, 1] ** 2\n","            randomCors.append(randomCor)\n","\n","          mosaic[y:y+100, x:x+100, :] = thisImage\n","\n","      improvements.append(np.mean(distances) - np.mean(randomDistances))\n","      all_cors.append(np.mean(cors))\n","      all_randomCors.append(np.mean(randomCors))\n","      # plt.figure(figsize=(10,10))\n","      # plt.imshow(cv2.cvtColor(mosaic, cv2.COLOR_BGR2RGB))\n","      # message = str(np.round(np.mean(distances), 2)) + \", \" + str(np.round(np.std(distances), 2)) + \"; \" + str(np.round(np.mean(randomDistances), 2)) + \", \" + str(np.round(np.std(randomDistances), 2))\n","      # plt.title(message)\n","      # plt.pause(0.0001)\n","  break"],"metadata":{"id":"822sC20jGeiP"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyM4Vn5ADA912Cd4KqkkL83r"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}